{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Numerical libraries\n",
    "import numpy as np   \n",
    "\n",
    "# Import Linear Regression machine learning library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# to handle data in form of rows and columns \n",
    "import pandas as pd    \n",
    "\n",
    "# importing ploting libraries\n",
    "import matplotlib.pyplot as plt   \n",
    "\n",
    "#importing seaborn for statistical plots\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df = pd.read_csv(\"car-mpg.csv\")  \n",
    "mpg_df = mpg_df.drop('car_name', axis=1)\n",
    "mpg_df['origin'] = mpg_df['origin'].replace({1: 'america', 2: 'europe', 3: 'asia'})\n",
    "mpg_df = pd.get_dummies(mpg_df, columns=['origin'])\n",
    "mpg_df = mpg_df.replace('?', np.nan)\n",
    "mpg_df = mpg_df.apply(lambda x: x.fillna(x.median()),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# separate independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all the predictor variables into X dataframe. Since 'mpg' is dependent variable drop it\n",
    "X = mpg_df.drop('mpg', axis=1)\n",
    "\n",
    "# Copy the 'mpg' column alone into the y dataframe. This is the dependent variable\n",
    "y = mpg_df[['mpg']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# scale all the columns of the mpg_df. This will produce a numpy array\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)  # ideally the training and test should be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Forward and Backward Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import add_constant\n",
    "X2 = add_constant(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "def forward_selected(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    while remaining and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit a simple linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for cyl is 2.5059518049385052\n",
      "The coefficient for disp is 2.535708286056052\n",
      "The coefficient for hp is -1.7889335736325254\n",
      "The coefficient for wt is -5.551819873098726\n",
      "The coefficient for acc is 0.11485734803440907\n",
      "The coefficient for yr is 2.931846548211611\n",
      "The coefficient for car_type is 2.977869737601943\n",
      "The coefficient for origin_america is -0.5832955290165979\n",
      "The coefficient for origin_asia is 0.3474931380432245\n",
      "The coefficient for origin_europe is 0.37741646808688323\n"
     ]
    }
   ],
   "source": [
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)\n",
    "\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, regression_model.coef_[0][idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a regularized RIDGE model and note the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model=Ridge(alpha=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for cyl is [2.5059518049385052, 1.4520179020254593]\n",
      "The coefficient for disp is [2.535708286056052, 0.9300879960464672]\n",
      "The coefficient for hp is [-1.7889335736325254, -1.6535616174264334]\n",
      "The coefficient for wt is [-5.551819873098726, -3.967353383122223]\n",
      "The coefficient for acc is [0.11485734803440907, -0.11819965764346413]\n",
      "The coefficient for yr is [2.931846548211611, 2.7280885802012826]\n",
      "The coefficient for car_type is [2.977869737601943, 2.2019288357544795]\n",
      "The coefficient for origin_america is [-0.5832955290165979, -0.5223468241979613]\n",
      "The coefficient for origin_asia is [0.3474931380432245, 0.3451933718440451]\n",
      "The coefficient for origin_europe is [0.37741646808688323, 0.30234911395905173]\n"
     ]
    }
   ],
   "source": [
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, [regression_model.coef_[0][idx],ridge_model.coef_[0][idx]]))\n",
    "#for idx, col_name in enumerate(X_train.columns):\n",
    " #   print(\"The coefficient for {} is {}\".format(col_name, ridge_model.coef_[0][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training  Score [0.8343770256960538, 0.8275133545583995]\n",
      " test Score [0.8513421387780066, 0.8569374430520706]\n"
     ]
    }
   ],
   "source": [
    "print(' training  Score',[regression_model.score(X_train,y_train),ridge_model.score(X_train,y_train)])\n",
    "print(' test Score',[regression_model.score(X_test,y_test),ridge_model.score(X_test,y_test)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge model: [[ 2.47057467  2.44494419 -1.78573889 -5.47285499  0.10115618  2.92319984\n",
      "   2.94492098 -0.57949986  0.34667456  0.37344909]]\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=.3)\n",
    "ridge.fit(X_train,y_train)\n",
    "print (\"Ridge model:\", (ridge.coef_))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a regularized LASSO model and note the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model: [ 1.83851731  1.19548187 -1.32260539 -4.8020951   0.          2.82349284\n",
      "  2.33448624 -0.82674844  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.05)\n",
    "lasso.fit(X_train,y_train)\n",
    "print (\"Lasso model:\", (lasso.coef_))\n",
    "\n",
    "# Observe, many of the coefficients have become 0 indicating drop of those dimensions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for cyl is 1.8385173123867278\n",
      "The coefficient for disp is 1.1954818725345313\n",
      "The coefficient for hp is -1.3226053859414477\n",
      "The coefficient for wt is -4.8020951012605035\n",
      "The coefficient for acc is 0.0\n",
      "The coefficient for yr is 2.8234928410713223\n",
      "The coefficient for car_type is 2.3344862378800255\n",
      "The coefficient for origin_america is -0.8267484380841996\n",
      "The coefficient for origin_asia is 0.0\n",
      "The coefficient for origin_europe is 0.0\n"
     ]
    }
   ],
   "source": [
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, lasso.coef_[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us compare their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8343770256960538\n",
      "0.8513421387780066\n"
     ]
    }
   ],
   "source": [
    "print(regression_model.score(X_train, y_train))\n",
    "print(regression_model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-a5fe7cf60bb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ridge' is not defined"
     ]
    }
   ],
   "source": [
    "print(ridge.score(X_train, y_train))\n",
    "print(ridge.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8322076784726787\n",
      "0.854995582934768\n"
     ]
    }
   ],
   "source": [
    "print(lasso.score(X_train, y_train))\n",
    "print(lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More or less similar results but with less complex models.  Complexity is a function of variables and coefficients\n",
    "## Note - with Lasso, we get equally good result in test though not so in training.  Further, the number of dimensions is much less\n",
    "# in LASSO model than ridge or un-regularized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us generate polynomial models reflecting the non-linear interaction between some dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree = 2, interaction_only=True)\n",
    "#poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 10)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 56)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_poly = poly.fit_transform(X_scaled)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.30, random_state=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        , -0.85632057, -0.8491159 , -1.08197717, -0.89317209,\n",
       "       -0.24256954,  1.35119925,  0.94141167,  0.77355903, -0.49764335,\n",
       "       -0.46196822,  0.72711541,  0.92651931,  0.76484164,  0.20771729,\n",
       "       -1.15705972, -0.80615018, -0.66241451,  0.42614224,  0.39559289,\n",
       "        0.91872401,  0.75840662,  0.20596966, -1.14732476, -0.79936761,\n",
       "       -0.65684127,  0.42255688,  0.39226456,  0.96639182,  0.26245471,\n",
       "       -1.46196675, -1.01858593, -0.83697321,  0.53843874,  0.49983907,\n",
       "        0.21665635, -1.20685347, -0.84084263, -0.69092134,  0.44448115,\n",
       "        0.41261712, -0.32775979, -0.2283578 , -0.18764186,  0.12071312,\n",
       "        0.11205942,  1.27203474,  1.04523239, -0.67241532, -0.62421111,\n",
       "        0.7282375 , -0.46848725, -0.43490227, -0.38495651, -0.35735969,\n",
       "        0.22989541])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a simple non regularized linear model on poly features-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.24082770e-13 -1.14204220e+12 -4.43738735e+00 -2.24947964e+00\n",
      " -2.98166341e+00 -1.56730367e+00  3.00442772e+00 -1.52060575e+12\n",
      " -7.80788356e+11  3.71375223e+12 -3.23609457e+12 -1.15918732e+00\n",
      " -1.43925476e+00 -3.57818604e-03  2.58444214e+00 -1.91918182e+00\n",
      " -3.65891647e+12 -6.45319147e+12 -2.39436996e+12 -2.28543203e+12\n",
      "  3.90441895e-01  2.09503174e-01 -4.23446655e-01  3.58471680e+00\n",
      " -2.02703094e+00 -9.03672940e+11 -7.44778888e+11 -7.10893285e+11\n",
      "  2.47772217e-01 -6.70440674e-01 -1.92620850e+00 -7.47558594e-01\n",
      " -2.15947171e+11 -1.77976884e+11 -1.69879374e+11 -1.72500610e-01\n",
      "  5.30212402e-01 -3.32050323e+00  1.69388998e+12  1.39605098e+12\n",
      "  1.33253411e+12  5.85876465e-01  1.53894043e+00  4.76389633e+11\n",
      "  3.92625390e+11  3.74761903e+11  4.00207520e-01 -1.27131857e+10\n",
      " -1.04778089e+10 -1.00010944e+10 -1.09798815e+12  8.13175594e+11\n",
      "  7.76178109e+11  2.20248210e+11 -5.15971535e+12  2.83957085e+12]\n"
     ]
    }
   ],
   "source": [
    "regression_model.fit(X_train, y_train)\n",
    "print(regression_model.coef_[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge model: [[ 0.          3.73512981 -2.93500874 -2.13974194 -3.56547812 -1.28898893\n",
      "   3.01290805  2.04739082  0.0786974   0.21972225 -0.3302341  -1.46231096\n",
      "  -1.17221896  0.00856067  2.48054694 -1.67596093  0.99537516 -2.29024279\n",
      "   4.7699338  -2.08598898  0.34009408  0.35024058 -0.41761834  3.06970569\n",
      "  -2.21649433  1.86339518 -2.62934278  0.38596397  0.12088534 -0.53440382\n",
      "  -1.88265835 -0.7675926  -0.90146842  0.52416091  0.59678246 -0.26349448\n",
      "   0.5827378  -3.02842915 -0.36548074  0.5956112  -0.15941014  0.49168856\n",
      "   1.45652375 -0.43819158 -0.20964198  0.77665496  0.36489921 -0.4750838\n",
      "   0.3551047   0.23188557 -1.42941282  2.06831543 -0.34986402 -0.32320394\n",
      "   0.39054656  0.06283411]]\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=.3)\n",
    "ridge.fit(X_train,y_train)\n",
    "print (\"Ridge model:\", (ridge.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9143225702003365\n",
      "0.8613398053698541\n"
     ]
    }
   ],
   "source": [
    "print(ridge.score(X_train, y_train))\n",
    "print(ridge.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model: [ 0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.57994956e+00\n",
      " -5.25925497e+00 -0.00000000e+00  2.87734427e+00  1.04842906e-02\n",
      " -1.21504098e-01  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  3.35421507e-01 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  1.70974264e-01 -0.00000000e+00\n",
      "  0.00000000e+00  1.15621326e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  3.63420040e-02  0.00000000e+00 -6.84544028e-01 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -7.61560567e-01  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  1.96273379e-01  0.00000000e+00 -6.52677925e-01\n",
      "  0.00000000e+00  3.59800528e-01  0.00000000e+00 -3.85308960e-01\n",
      "  4.51963503e-03  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  1.65720500e-01 -0.00000000e+00  0.00000000e+00 -0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.09)\n",
    "lasso.fit(X_train,y_train)\n",
    "print (\"Lasso model:\", (lasso.coef_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8908510504987864\n",
      "0.8798857278694309\n"
     ]
    }
   ],
   "source": [
    "print(lasso.score(X_train, y_train))\n",
    "print(lasso.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
